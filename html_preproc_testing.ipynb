{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624e053d-9cfa-4cc1-a689-e4f1c97fa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString, CData, Tag\n",
    "from io import BytesIO\n",
    "import PyPDF2\n",
    "import ssl\n",
    "import certifi\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "class MyBeautifulSoup(BeautifulSoup):\n",
    "    def _all_strings_plus(  self, strip=True, types=NavigableString, \n",
    "                                aRef={'a': lambda a: f\"<{a.get('href', '')}>\"}, \n",
    "                                skipTags=['script', 'style']    ):\n",
    "        # verify types\n",
    "        if hasattr(types,'__iter__') and not isinstance(types,type):\n",
    "            types = tuple([t for t in types if isinstance(t, type)])\n",
    "        if not (types and isinstance(types,(type,tuple))): types = NavigableString\n",
    "        \n",
    "        # skip text in tags included in aRef\n",
    "        skipTags += list(aRef.keys())\n",
    "        \n",
    "        for descendant in self.descendants:\n",
    "            # yield extra strings according to aRef\n",
    "            if isinstance(descendant, Tag) and descendant.name in aRef:\n",
    "                extraStr = aRef[descendant.name](descendant)\n",
    "                if isinstance(extraStr, str): yield extraStr\n",
    "\n",
    "            # skip text nodes DIRECTLY inside a Tag in aRef\n",
    "            if descendant.parent.name in aRef: continue\n",
    "\n",
    "            # skip ALL text nodes inside skipTags \n",
    "            if skipTags and descendant.find_parent(skipTags): continue\n",
    "\n",
    "            # default behavior\n",
    "            if not isinstance(descendant, types): continue\n",
    "\n",
    "            if strip:\n",
    "                descendant = descendant.strip()\n",
    "                if len(descendant) == 0: continue\n",
    "            yield descendant\n",
    "    \n",
    "    def get_text_plus(self, separator=\" \", srcUrl=None, **aspArgs):\n",
    "        if srcUrl and isinstance(srcUrl, str):\n",
    "            def hrefStr(aTag):\n",
    "                href = aTag.get('href')\n",
    "                if not (href is None or href.startswith('javascript')):\n",
    "                    return f\"<{urljoin(srcUrl, href)}>\"\n",
    "            aspArgs.setdefault('aRef', {})\n",
    "            aspArgs['aRef']['a'] = hrefStr\n",
    "        \n",
    "        return separator.join(self._all_strings_plus(**aspArgs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606bcd98-0be1-4067-9a49-a30ff29b6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6feaa38-d729-4326-bed2-998d592c8c77",
   "metadata": {},
   "source": [
    "### BeautifulSoup & PDF testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce942fcf-23fe-4e31-9855-a51a51cac085",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_html = requests.get('https://azure-na-assets.contentstack.com/v3/assets/blt71bfe6e8a1c2d265/bltc320e2642a070852/Exelon_Environment_Policy_Poster-8.5x11v2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44efdff7-76c8-4783-b131-9928b64ad770",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = source_html.content\n",
    "with BytesIO(raw_data) as data:\n",
    "    read_pdf = PyPDF2.PdfFileReader(data)\n",
    "\n",
    "    for page in range(read_pdf.getNumPages()):\n",
    "        print(read_pdf.getPage(page).extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da7e7c73-8888-4b8d-af0a-81ab74858395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "url = 'https://data.sec.gov/submissions/CIK0000009466.json'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36', 'Accept-Encoding': 'gzip, deflate', 'host': 'www.sec.gov'}\n",
    "session.headers.update(headers)\n",
    "response = session.get(url, verify=certifi.where())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95e13700-8f02-4289-9195-274bd8555c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cdb355-0fef-4fd7-96c7-b6b3dcd5bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = MyBeautifulSoup(source_html.text, 'html.parser')\n",
    "# soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a8e020-2431-4f4c-a0e0-036f56793ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in soup(['script', 'style']):\n",
    "    script.decompose()\n",
    "len(soup.get_text_plus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94f17d-2f9c-47ef-9c33-88ca5330f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_links_parsed = ' '.join(soup.get_text_plus().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1de85c-9966-4693-84d8-8587995b94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.get_text_plus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582795e-fc7b-4f7f-8028-69bb3e3d68db",
   "metadata": {},
   "source": [
    "### Selenium Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2984a7b4-24be-45dd-9df5-8d81de09edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively find text in all iframes in a web page. Maybe I dont need this. \n",
    "def find_all_iframes(driver) -> list:\n",
    "    iframes = driver.find_elements_by_xpath(\"//iframe\")\n",
    "    text_per_frame = []\n",
    "    print(iframes)\n",
    "    frame_soup = MyBeautifulSoup(driver.page_source, 'html.parser')\n",
    "    frame_text_links = frame_soup.get_text_plus()\n",
    "    text_per_frame.append(frame_text_links)\n",
    "    for index, iframe in enumerate(iframes):\n",
    "        # Your sweet business logic applied to iframe goes here.\n",
    "        driver.switch_to.frame(index)\n",
    "        # html = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "        frame_soup = MyBeautifulSoup(driver.page_source, 'html.parser')\n",
    "        frame_text_links = frame_soup.get_text_plus()\n",
    "        text_per_frame.append(frame_text_links)\n",
    "        nested_iframe_text = find_all_iframes(driver)\n",
    "        if nested_iframe_text:\n",
    "            text_per_frame.append(nested_iframe_text)\n",
    "        driver.switch_to.parent_frame()\n",
    "        \n",
    "    return text_per_frame\n",
    "\n",
    "\n",
    "def url_inline_text(soup):\n",
    "    # Remove script and style elements\n",
    "    for script_or_style in soup(['script', 'style']):\n",
    "        script_or_style.decompose()\n",
    "    \n",
    "    # # Remove comment elements\n",
    "    # for comment in soup.find_all(text=lambda text: isinstance(text, Comment)):\n",
    "    #     comment.extract()\n",
    "    \n",
    "    # Replace links with text and URL\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        if a['href'].startswith('javascript') or len(a['href']) < 2:\n",
    "            a.decompose()\n",
    "        else:\n",
    "            a.replace_with(f\"{a.get_text()} ({a['href']})\")\n",
    "\n",
    "    return soup\n",
    "\n",
    "def get_shadow_root_text(driver, wait) -> list:\n",
    "    # Augment HTML with text in shadow DOM\n",
    "    shdw_dom_text = []\n",
    "    all_elements = wait.until(EC.presence_of_all_elements_located((By.XPATH, '//*')))\n",
    "    for el in all_elements:\n",
    "        try:\n",
    "            if driver.execute_script('return arguments[0].shadowRoot', el):\n",
    "                \n",
    "                shdw_el = driver.execute_script(f\"return document.querySelector('{el.tag_name}').shadowRoot.querySelector('div')\")\n",
    "                # print(shdw_el.find_elements(By.CSS_SELECTOR, \"p\"))\n",
    "                frame_soup = url_inline_text(BeautifulSoup(shdw_el.get_attribute('innerHTML'), 'html.parser'))\n",
    "                # frame_text_links = frame_soup.get_text_plus()\n",
    "                # print('-'*25)\n",
    "                # print(frame_soup.get_text(separator='\\n'))\n",
    "                shdw_dom_text.append(frame_soup.get_text(separator=' | '))\n",
    "                \n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return shdw_dom_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "35101cfd-a777-4ea5-a8d9-7ef15e36b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute that contains HTML of current page. Reference to Selenium methods\n",
    "drop_downs = driver.find_element(By.CSS_SELECTOR, \"body\")#.shadow_root\n",
    "driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "# spans = driver.find_elements_by_class_name('euds-accordion')\n",
    "# print([span.text for span in spans])\n",
    "\n",
    "# shadow_dict = driver.execute_script('return arguments[0].shadowRoot', drop_downs)\n",
    "data = driver.execute_script('return arguments[0].shadowRoot', drop_downs)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a899bc25-e311-4c4d-aba6-3b748aead1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create web driver object\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('C:\\\\Users\\\\14102\\\\Brown\\\\Internships\\\\INL\\\\CRMM_Scraping\\\\chromedriver-win64\\\\chromedriver-win64\\\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "faf3a6e6-8844-4e00-993e-53090755cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to navigate to provided URL\n",
    "actions = ActionChains(driver)\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.get('https://www.bge.com/safety-community/environment/our-initiatives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "50be94a2-0372-4c51-a849-417b7d793c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HTML from main DOM\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "soup = url_inline_text(soup)\n",
    "# Get text, excluding any residual JavaScript or CSS\n",
    "main_html_text = soup.get_text(separator=' | ', strip=True)\n",
    "\n",
    "# Get any text from shadow root\n",
    "shadow_html_text_list = get_shadow_root_text(driver, wait)\n",
    "\n",
    "full_html = '|'.join([main_html_text] + shadow_html_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5e126774-c0ee-457d-bb07-9c9c8a1e502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ed11fe21-cc56-47da-96c5-67ce1fc0fffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shadow_html_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0ba43-8480-42ec-805a-13483ceb4a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
